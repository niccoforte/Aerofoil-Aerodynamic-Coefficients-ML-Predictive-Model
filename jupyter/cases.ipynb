{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec7c3c1-2a61-446d-ba80-590283135007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naca1.dat failed. ERROR: float division by zero\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import urllib.request as urllib2\n",
    "import pandas as pd\n",
    "\n",
    "%run aerofoils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a142ab2-8b83-4d46-a8da-4400c777d4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_AFT_cases(directory='dat/case-dat'):\n",
    "    baseFlpth = \"http://airfoiltools.com\"\n",
    "\n",
    "    html_all = urllib2.urlopen(\"http://airfoiltools.com/search/airfoils\").read()\n",
    "    soup_all = BeautifulSoup(html_all,'html.parser')    \n",
    "    \n",
    "    links_all = [link['href'] for link in soup_all.find_all('a', href=re.compile(\"/airfoil/details\"))]\n",
    "    \n",
    "    linknames = [link[25:-3].lower() for link in links_all]\n",
    "    filenames_dir = [str(file)[11:].lower() for file in os.scandir(directory)]\n",
    "    linknames_new = []\n",
    "    for name in linknames:\n",
    "        count = 0\n",
    "        for filename in filenames_dir:\n",
    "            if name in filename:\n",
    "                count += 1\n",
    "            else:\n",
    "                continue\n",
    "        if count > 3:\n",
    "            continue\n",
    "        else:\n",
    "            linknames_new.append(name)\n",
    "    links_new = []\n",
    "    for new in linknames_new:\n",
    "        for link in links_all:\n",
    "            if new in link:\n",
    "                links_new.append(link)\n",
    "                    \n",
    "    print('Staring AFT Case download...')\n",
    "    indx = 0\n",
    "    for link in links_new:\n",
    "        html_foil = urllib2.urlopen(baseFlpth + link).read()\n",
    "        soup_foil = BeautifulSoup(html_foil,'html.parser')\n",
    "        \n",
    "        links_Re = [link_Re['href'] for link_Re in soup_foil.find_all('a', href=re.compile(\"/polar/details\"))]\n",
    "        for link_Re in links_Re:\n",
    "            if link_Re.endswith('-n5'):\n",
    "                continue\n",
    "            elif link_Re.endswith('-n1'):\n",
    "                continue\n",
    "\n",
    "            html_Re = urllib2.urlopen(baseFlpth + link_Re).read()\n",
    "            soup_Re = BeautifulSoup(html_Re,'html.parser')\n",
    "            \n",
    "            link_csv = soup_Re.find_all('a', href=re.compile(\"polar/csv\"))[0]['href']\n",
    "            \n",
    "            name = link_csv[20:] + '.csv'\n",
    "            fullfilename = os.path.join(directory, name)\n",
    "            urllib2.urlretrieve(baseFlpth+link_csv, fullfilename)\n",
    "        \n",
    "            indx += 1\n",
    "        \n",
    "    print(f' Done. {indx} files copied from http://airfoiltools.com/search/airfoils and saved to ~/{directory}.')\n",
    "\n",
    "\n",
    "def get_RENNES_cases(directory='dat/rennes-dat/case-dat'):\n",
    "    baseFlpth = \"https://perso.univ-rennes1.fr/laurent.blanchard/Profils/\"\n",
    "\n",
    "    html_all = urllib2.urlopen(baseFlpth).read()\n",
    "    soup_all = BeautifulSoup(html_all,'html.parser') \n",
    "        \n",
    "    links_all = [link['href'] for link in soup_all.find_all('a', href=re.compile(\"/index\"))]\n",
    "    links_all.remove('centrepoussee/index.html')\n",
    "    links_all.remove('clouet/index.html')\n",
    "    \n",
    "    linknames = [link[:-11].lower() for link in links_all]\n",
    "    filenames_dir = [str(file)[11:].split('-')[0].lower() for file in os.scandir(directory)]\n",
    "    linknames_new = []\n",
    "    for name in linknames:\n",
    "        count = 0\n",
    "        for filename in filenames_dir:\n",
    "            if name in filename:\n",
    "                count += 1\n",
    "            else:\n",
    "                continue\n",
    "        if count > 5:\n",
    "            continue\n",
    "        else:\n",
    "            linknames_new.append(name)\n",
    "    links_new = []\n",
    "    for new in linknames_new:\n",
    "        for link in links_all:\n",
    "            if new in link:\n",
    "                links_new.append(link)\n",
    "                                    \n",
    "    print('Staring RENNES Case download...')\n",
    "    indx = 0\n",
    "    for link in links_new: \n",
    "        try:\n",
    "            html_foil = urllib2.urlopen(baseFlpth + link).read()\n",
    "            soup_foil = BeautifulSoup(html_foil,'html.parser')\n",
    "\n",
    "            links_Re = [link_Re['href'] for link_Re in soup_foil.find_all('a', href=re.compile(\".txt\"))]\n",
    "\n",
    "            for link_Re in links_Re:\n",
    "                name = link[:-11] + '-' + link_Re\n",
    "                fullfilename = os.path.join(directory, name)\n",
    "                urllib2.urlretrieve(baseFlpth+link[:-10]+link_Re, fullfilename)\n",
    "\n",
    "                indx += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass  # print(e)\n",
    "    \n",
    "    print(f' Done. {indx} files copied from {baseFlpth} and saved to ~/{directory}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af3b4359-efc3-48b1-9b6f-9a4369e22819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get_AFT_cases(directory='dat/case-dat')\n",
    "# get_RENNES_cases(directory='dat/rennes-dat/case-dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6cf687-63b9-4f25-b1c0-7170b1ebca2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_AFTcase(file):\n",
    "    top = pd.read_csv(file, nrows=8)\n",
    "    bottom = pd.read_csv(file, skiprows=9)\n",
    "    \n",
    "    name = top.iloc[1,0][:-3].lower().replace('.','').replace('_','-')\n",
    "    Re = float(top.iloc[2,0])\n",
    "    \n",
    "    alphas = []\n",
    "    Cls = []\n",
    "    Cds = []\n",
    "    for indx, row in bottom.iterrows():\n",
    "        alpha = float(row.Alpha)\n",
    "        Cl = float(row.Cl)\n",
    "        Cd = float(row.Cd)\n",
    "        \n",
    "        alphas.append(alpha)\n",
    "        Cls.append(Cl)\n",
    "        Cds.append(Cd)\n",
    "    \n",
    "    return name, Re, alphas, Cls, Cds\n",
    "\n",
    "\n",
    "def read_RENcase(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        dat = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            dat.append(line)\n",
    "    \n",
    "    name = str(file)[11:-6].split('-')[0].replace('_','-')\n",
    "    Re = float(dat[8][28:33]) * 10**6\n",
    "    dat = dat[12:]\n",
    "    \n",
    "    alphas = []\n",
    "    Cls = []\n",
    "    Cds = []\n",
    "    for row in dat:\n",
    "        row = row.split('  ')\n",
    "        alpha = float(row[0])\n",
    "        Cl = float(row[1])\n",
    "        Cd = float(row[2])\n",
    "\n",
    "        alphas.append(alpha)\n",
    "        Cls.append(Cl)\n",
    "        Cds.append(Cd)\n",
    "        \n",
    "    return name, Re, alphas, Cls, Cds\n",
    "\n",
    "\n",
    "def read_EXPcase(file):\n",
    "    dat = pd.read_csv(file)\n",
    "    \n",
    "    name = dat.file.tolist()\n",
    "    Re = dat.Re.tolist()\n",
    "    alphas = dat.alpha.tolist()\n",
    "    Cls = dat.Cl.tolist()\n",
    "    Cds = dat.Cd.tolist()\n",
    "    \n",
    "    return name, Re, alphas, Cls, Cds\n",
    "\n",
    "\n",
    "def create_cases(directory='dat/case-dat', ext='csv'):\n",
    "    cases_df = pd.DataFrame(columns=['file', 'Re', 'alpha', 'Cl', 'Cd'])\n",
    "    \n",
    "    for file in os.scandir(directory):\n",
    "        if file.name.endswith('.' + ext):\n",
    "            try:\n",
    "                if directory == 'dat/case-dat':\n",
    "                    name, Re, alphas, Cls, Cds = read_AFTcase(file)\n",
    "                    name = [name.lower()] * len(alphas)\n",
    "                    Re = [Re] * len(alphas)\n",
    "                elif directory == 'dat/rennes-dat/case-dat':\n",
    "                    name, Re, alphas, Cls, Cds = read_RENcase(file)\n",
    "                    name = [name.lower()] * len(alphas)\n",
    "                    Re = [Re] * len(alphas)\n",
    "                elif directory == 'dat/exp-dat/case-dat':\n",
    "                    name, Re, alphas, Cls, Cds = read_EXPcase(file)\n",
    "                    \n",
    "                case_df = pd.DataFrame({'file': name, 'Re': Re, 'alpha': alphas, 'Cl': Cls, 'Cd': Cds})\n",
    "                cases_df = pd.concat([cases_df, case_df], ignore_index=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                pass  # print(e)\n",
    "    \n",
    "    cases_df = cases_df.sort_values(['file', 'Re', 'alpha'], ignore_index=True)\n",
    "    return cases_df\n",
    "\n",
    "\n",
    "def merge(cases_df, aerofoils_df):\n",
    "    cases_df['right_index'] = cases_df.index.tolist()\n",
    "\n",
    "    totdata_df = pd.merge(aerofoils_df, cases_df, on='file', how='outer', indicator=True)\n",
    "    data_df = totdata_df.loc[totdata_df._merge == 'both'].drop(columns=['_merge'])\n",
    "\n",
    "    dup, inds = list(data_df.right_index.duplicated()), data_df.index.tolist()\n",
    "    dup_inds = [i for i, d in zip(inds,dup) if d is True]\n",
    "    data_df = data_df[~data_df.index.isin(dup_inds)].drop(columns=['right_index'])\n",
    "    data_df = data_df.sort_values(['file', 'Re'], ascending=[True, True])\n",
    "\n",
    "    return cases_df, totdata_df, data_df\n",
    "\n",
    "\n",
    "def save_cases(df, file):\n",
    "    df.to_csv(file, index=False)\n",
    "    \n",
    "    \n",
    "def df_from_csv(file):\n",
    "    df = pd.read_csv(file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7750418c-4ecc-4a7f-9273-9f05909202fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cases_df = create_cases(directory='dat/case-dat', ext='csv')\n",
    "# save_cases(df=cases_df, file='dat-saved/cases-df.csv')\n",
    "# \n",
    "# ren_cases_df = create_cases(directory='dat/rennes-dat/case-dat', ext='txt')\n",
    "# save_cases(df=ren_cases_df, file='dat-saved/ren-cases-df.csv')\n",
    "# \n",
    "# exp_cases_df = create_cases(directory='dat/exp-dat/case-dat', ext='csv')\n",
    "# save_cases(df=exp_cases_df, file='dat-saved/exp-cases-df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f3a6612-6351-424b-aa50-4ed03ebb764d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cases_df = df_from_csv(file='dat-saved/cases-df.csv')\n",
    "ren_cases_df = df_from_csv(file='dat-saved/ren-cases-df.csv')\n",
    "exp_cases_df = df_from_csv(file='dat-saved/exp-cases-df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69895aee-3a29-4530-8f1a-70514e6c7d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 829544 831325 829544\n",
      "Rennes: 31526 31527 27641\n",
      "Experimental: 1012 2664 1012\n"
     ]
    }
   ],
   "source": [
    "cases_df, totdata_df, data_df = merge(aerofoils_df=aerofoils_df, cases_df=cases_df)\n",
    "print('Normal:', len(cases_df), len(totdata_df), len(data_df))\n",
    "\n",
    "ren_cases_df, ren_totdata_df, ren_data_df = merge(aerofoils_df=ren_aerofoils_df, cases_df=ren_cases_df)\n",
    "print('Rennes:', len(ren_cases_df), len(ren_totdata_df), len(ren_data_df))\n",
    "\n",
    "exp_cases_df, exp_totdata_df, exp_data_df = merge(aerofoils_df=aerofoils_df, cases_df=exp_cases_df)\n",
    "print('Experimental:', len(exp_cases_df), len(exp_totdata_df), len(exp_data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3f4358b-38c6-4b83-b4ef-f83d759c5551",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_df.sample(frac=0.00001).drop(columns = ['spline', 'xy_profile'])\n",
    "# list(set(ren_data_df.file.tolist()))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b955cc7-e04f-435f-b073-70fd9695acc8",
   "metadata": {},
   "source": [
    "from ExtractTable import ExtractTable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d00180a7-6ed1-43dd-800d-ad23c3bb2467",
   "metadata": {},
   "source": [
    "et_sess = ExtractTable(api_key='ZLl0Rz3g5gLTSGF6vb3V9EnSutNoimfvWBjYnphH')\n",
    "print(et_sess.check_usage())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b575ff4a-c4ce-4cb7-adc2-43c6587900b6",
   "metadata": {},
   "source": [
    "#table_data = et_sess.process_file(filepath='dat/exp-dat/t-sheldahl.pdf', output_format=\"json\", pages='62-64')\n",
    "df1 = pd.concat([pd.read_json(df) for df in table_data])\n",
    "df1.to_csv('dat/exp-dat/new.csv', index=False)\n",
    "df1 = pd.read_csv('dat/exp-dat/new.csv').iloc[32:]\n",
    "df1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f586b80-cfa9-49c5-9715-26303974805b",
   "metadata": {
    "tags": []
   },
   "source": [
    "df2 = pd.read_csv('dat/exp-dat/sheld-n0021.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8180268a-e62e-4121-83bd-1acc58f8cc3c",
   "metadata": {},
   "source": [
    "df = pd.concat([df2, df1])\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1330f746-cff3-42ee-b747-c7f608177792",
   "metadata": {},
   "source": [
    "df.to_csv('dat/exp-dat/sheld-n0021.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8cf7c9b6-2504-4b67-8ba1-827159b5bfac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "3705c6ec-f5dd-4e15-bb67-9c95686e591e",
   "metadata": {},
   "source": [
    "ch = pd.read_csv('dat/exp-dat/sheld-n0021.csv')\n",
    "ch = ch.drop(0).drop(columns=['0','4'])\n",
    "ch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ddf6a9f8-6b57-4ddb-a844-d6c3478db82b",
   "metadata": {},
   "source": [
    "As, Ls, Ds = [], [], []\n",
    "for a, l, d in zip(ch['1'].tolist(), ch['2'].tolist(), ch['3'].tolist()):\n",
    "    try:\n",
    "        a = float(a)\n",
    "        l = float(l)\n",
    "        d = float(d)\n",
    "        As.append(a)\n",
    "        Ls.append(l)\n",
    "        Ds.append(d)\n",
    "    except Exception as e:        \n",
    "        try:\n",
    "            two_a = a.split(' ')\n",
    "            two_l = l.split(' ')\n",
    "            two_d = d.split(' ')\n",
    "            As.append(two_a[0])\n",
    "            As.append(two_a[1])\n",
    "            Ls.append(two_l[0])\n",
    "            Ls.append(two_l[1])\n",
    "            Ds.append(two_d[0])\n",
    "            Ds.append(two_d[1])\n",
    "        except Exception as e: \n",
    "            As.append(a)\n",
    "            Ls.append(l)\n",
    "            Ds.append(d)\n",
    "\n",
    "\n",
    "ch = pd.DataFrame({'a':As, 'l':Ls, 'd':Ds})\n",
    "ch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72a978ff-1370-4064-8689-a8d174481396",
   "metadata": {},
   "source": [
    "ch.to_csv('dat/exp-dat/sheld-n0021.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aac628a8-b0b1-4b0f-b65d-88ef35f7d09f",
   "metadata": {},
   "source": [
    "ch = pd.read_csv('dat/exp-dat/sheld-n0021.csv')\n",
    "\n",
    "ch.alpha = ch.alpha.astype(float)\n",
    "ch.Cl = ch.Cl.astype(float)\n",
    "ch.Cd = ch.Cd.astype(float)\n",
    "\n",
    "\n",
    "print([i for i in ch.Cl.tolist() if i > 1.5])\n",
    "ch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "533fd364-2201-42eb-a467-a2f29139ec20",
   "metadata": {},
   "source": [
    "negs = ch.copy()\n",
    "negs = negs[negs.alpha != 0.0]\n",
    "negs.alpha = [-i for i in negs.alpha.tolist()]\n",
    "negs.Cl = [-i for i in negs.Cl.tolist()]\n",
    "done = pd.concat([ch, negs], ignore_index=True)\n",
    "done = done.sort_values(['file','Re','alpha'])\n",
    "done"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06694061-4661-431d-9a00-8e01d6c0a28f",
   "metadata": {},
   "source": [
    "done.to_csv('dat/exp-dat/sheld-n0021.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ef51b5e-4655-4fef-ab71-2150e240e19e",
   "metadata": {},
   "source": [
    "df = df.drop(columns=[1, 2, 3])\n",
    "df = df.drop([0, 1, 2, 3, 4, 9, 10, 11])\n",
    "df = df.rename(columns={0: 'alpha', 4: 'Cl'})\n",
    "df.alpha = [float(ang[:-1]) for ang in df.alpha.tolist()]\n",
    "df = df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87907b44-f859-4a29-b12a-88ac455b6532",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93c29e57-979b-464c-a631-93f074b37712",
   "metadata": {},
   "source": [
    "name = 's809'\n",
    "re = '3e6'\n",
    "\n",
    "l = pd.read_csv(f'dat/exp-dat/eleni/done/{name}-{re}-l.csv', index_col=0)\n",
    "d = pd.read_csv(f'dat/exp-dat/eleni/done/{name}-{re}-d.csv', index_col=0)\n",
    "ld = l.merge(d, how='outer', on='alpha')\n",
    "ld.alpha = [float(a) for a in ld.alpha.tolist()]\n",
    "ld.Cl = [float(l.replace(',', '.')) if type(l) == str else np.nan for l in ld.Cl.tolist()]\n",
    "ld.Cd = [float(d.replace(',', '.')) if type(d) == str else np.nan for d in ld.Cd.tolist()]\n",
    "ld.insert(0, 'file', [name]*len(ld))\n",
    "ld.insert(1, 'Re', [float(re)]*len(ld))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60ac49b9-13a8-452b-87b3-c181b73bacd5",
   "metadata": {},
   "source": [
    "ld"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b409ab5c-c73f-432c-bbbc-db00c9516228",
   "metadata": {},
   "source": [
    "ld.to_csv(f'dat/exp-dat/eleni/done/{name}-{re}.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf2b3035-b717-4c78-8775-cc71a4a0b6be",
   "metadata": {},
   "source": [
    "DF = df1.merge(df2, how='outer', on='Cl')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6064d698-132d-498b-8664-7625c33baceb",
   "metadata": {},
   "source": [
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
