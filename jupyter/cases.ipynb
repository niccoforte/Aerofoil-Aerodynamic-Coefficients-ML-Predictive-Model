{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec7c3c1-2a61-446d-ba80-590283135007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naca1.dat failed. ERROR: float division by zero\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import urllib.request as urllib2\n",
    "import pandas as pd\n",
    "\n",
    "%run aerofoils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a142ab2-8b83-4d46-a8da-4400c777d4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_AFT_cases(directory='dat/case-dat'):\n",
    "    baseFlpth = \"http://airfoiltools.com\"\n",
    "\n",
    "    html_all = urllib2.urlopen(\"http://airfoiltools.com/search/airfoils\").read()\n",
    "    soup_all = BeautifulSoup(html_all,'html.parser')    \n",
    "    \n",
    "    links_all = [link['href'] for link in soup_all.find_all('a', href=re.compile(\"/airfoil/details\"))]\n",
    "    \n",
    "    linknames = [link[25:-3].lower() for link in links_all]\n",
    "    filenames_dir = [str(file)[11:].lower() for file in os.scandir(directory)]\n",
    "    linknames_new = []\n",
    "    for name in linknames:\n",
    "        count = 0\n",
    "        for filename in filenames_dir:\n",
    "            if name in filename:\n",
    "                count += 1\n",
    "            else:\n",
    "                continue\n",
    "        if count > 3:\n",
    "            continue\n",
    "        else:\n",
    "            linknames_new.append(name)\n",
    "    links_new = []\n",
    "    for new in linknames_new:\n",
    "        for link in links_all:\n",
    "            if new in link:\n",
    "                links_new.append(link)\n",
    "                    \n",
    "    print('Staring AFT Case download...')\n",
    "    indx = 0\n",
    "    for link in links_new:\n",
    "        html_foil = urllib2.urlopen(baseFlpth + link).read()\n",
    "        soup_foil = BeautifulSoup(html_foil,'html.parser')\n",
    "        \n",
    "        links_Re = [link_Re['href'] for link_Re in soup_foil.find_all('a', href=re.compile(\"/polar/details\"))]\n",
    "        for link_Re in links_Re:\n",
    "            if link_Re.endswith('-n5'):\n",
    "                continue\n",
    "            elif link_Re.endswith('-n1'):\n",
    "                continue\n",
    "\n",
    "            html_Re = urllib2.urlopen(baseFlpth + link_Re).read()\n",
    "            soup_Re = BeautifulSoup(html_Re,'html.parser')\n",
    "            \n",
    "            link_csv = soup_Re.find_all('a', href=re.compile(\"polar/csv\"))[0]['href']\n",
    "            \n",
    "            name = link_csv[20:] + '.csv'\n",
    "            fullfilename = os.path.join(directory, name)\n",
    "            urllib2.urlretrieve(baseFlpth+link_csv, fullfilename)\n",
    "        \n",
    "            indx += 1\n",
    "        \n",
    "    print(f' Done. {indx} files copied from http://airfoiltools.com/search/airfoils and saved to ~/{directory}.')\n",
    "\n",
    "\n",
    "def get_RENNES_cases(directory='dat/rennes-dat/case-dat'):\n",
    "    baseFlpth = \"https://perso.univ-rennes1.fr/laurent.blanchard/Profils/\"\n",
    "\n",
    "    html_all = urllib2.urlopen(baseFlpth).read()\n",
    "    soup_all = BeautifulSoup(html_all,'html.parser') \n",
    "        \n",
    "    links_all = [link['href'] for link in soup_all.find_all('a', href=re.compile(\"/index\"))]\n",
    "    links_all.remove('centrepoussee/index.html')\n",
    "    links_all.remove('clouet/index.html')\n",
    "    \n",
    "    linknames = [link[:-11].lower() for link in links_all]\n",
    "    filenames_dir = [str(file)[11:].split('-')[0].lower() for file in os.scandir(directory)]\n",
    "    linknames_new = []\n",
    "    for name in linknames:\n",
    "        count = 0\n",
    "        for filename in filenames_dir:\n",
    "            if name in filename:\n",
    "                count += 1\n",
    "            else:\n",
    "                continue\n",
    "        if count > 5:\n",
    "            continue\n",
    "        else:\n",
    "            linknames_new.append(name)\n",
    "    links_new = []\n",
    "    for new in linknames_new:\n",
    "        for link in links_all:\n",
    "            if new in link:\n",
    "                links_new.append(link)\n",
    "                                    \n",
    "    print('Staring RENNES Case download...')\n",
    "    indx = 0\n",
    "    for link in links_new: \n",
    "        try:\n",
    "            html_foil = urllib2.urlopen(baseFlpth + link).read()\n",
    "            soup_foil = BeautifulSoup(html_foil,'html.parser')\n",
    "\n",
    "            links_Re = [link_Re['href'] for link_Re in soup_foil.find_all('a', href=re.compile(\".txt\"))]\n",
    "\n",
    "            for link_Re in links_Re:\n",
    "                name = link[:-11] + '-' + link_Re\n",
    "                fullfilename = os.path.join(directory, name)\n",
    "                urllib2.urlretrieve(baseFlpth+link[:-10]+link_Re, fullfilename)\n",
    "\n",
    "                indx += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass  # print(e)\n",
    "    \n",
    "    print(f' Done. {indx} files copied from {baseFlpth} and saved to ~/{directory}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af3b4359-efc3-48b1-9b6f-9a4369e22819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get_AFT_cases(directory='dat/case-dat')\n",
    "# get_RENNES_cases(directory='dat/rennes-dat/case-dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6cf687-63b9-4f25-b1c0-7170b1ebca2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_AFTcase(file):\n",
    "    top = pd.read_csv(file, nrows=8)\n",
    "    bottom = pd.read_csv(file, skiprows=9)\n",
    "    \n",
    "    name = top.iloc[1,0][:-3].lower().replace('.','').replace('_','-')\n",
    "    Re = float(top.iloc[2,0])\n",
    "    \n",
    "    alphas = []\n",
    "    Cls = []\n",
    "    Cds = []\n",
    "    for indx, row in bottom.iterrows():\n",
    "        alpha = float(row.Alpha)\n",
    "        Cl = float(row.Cl)\n",
    "        Cd = float(row.Cd)\n",
    "        \n",
    "        alphas.append(alpha)\n",
    "        Cls.append(Cl)\n",
    "        Cds.append(Cd)\n",
    "    \n",
    "    return name, Re, alphas, Cls, Cds\n",
    "\n",
    "\n",
    "def read_RENcase(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        dat = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            dat.append(line)\n",
    "    \n",
    "    name = str(file)[11:-6].split('-')[0].replace('_','-')\n",
    "    Re = float(dat[8][28:33]) * 10**6\n",
    "    dat = dat[12:]\n",
    "    \n",
    "    alphas = []\n",
    "    Cls = []\n",
    "    Cds = []\n",
    "    for row in dat:\n",
    "        row = row.split('  ')\n",
    "        alpha = float(row[0])\n",
    "        Cl = float(row[1])\n",
    "        Cd = float(row[2])\n",
    "\n",
    "        alphas.append(alpha)\n",
    "        Cls.append(Cl)\n",
    "        Cds.append(Cd)\n",
    "        \n",
    "    return name, Re, alphas, Cls, Cds\n",
    "\n",
    "\n",
    "def read_EXPcase(file):\n",
    "    dat = pd.read_csv(file)\n",
    "    \n",
    "    name = dat.file.tolist()\n",
    "    Re = dat.Re.tolist()\n",
    "    alphas = dat.alpha.tolist()\n",
    "    Cls = dat.Cl.tolist()\n",
    "    Cds = dat.Cd.tolist()\n",
    "    \n",
    "    return name, Re, alphas, Cls, Cds\n",
    "\n",
    "\n",
    "def create_cases(directory='dat/case-dat', ext='csv'):\n",
    "    cases_df = pd.DataFrame(columns=['file', 'Re', 'alpha', 'Cl', 'Cd'])\n",
    "    \n",
    "    for file in os.scandir(directory):\n",
    "        if file.name.endswith('.' + ext):\n",
    "            try:\n",
    "                if directory == 'dat/case-dat':\n",
    "                    name, Re, alphas, Cls, Cds = read_AFTcase(file)\n",
    "                    name = [name.lower()] * len(alphas)\n",
    "                    Re = [Re] * len(alphas)\n",
    "                elif directory == 'dat/rennes-dat/case-dat':\n",
    "                    name, Re, alphas, Cls, Cds = read_RENcase(file)\n",
    "                    name = [name.lower()] * len(alphas)\n",
    "                    Re = [Re] * len(alphas)\n",
    "                elif directory == 'dat/exp-dat/case-dat':\n",
    "                    name, Re, alphas, Cls, Cds = read_EXPcase(file)\n",
    "                    \n",
    "                case_df = pd.DataFrame({'file': name, 'Re': Re, 'alpha': alphas, 'Cl': Cls, 'Cd': Cds})\n",
    "                cases_df = pd.concat([cases_df, case_df], ignore_index=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                pass  # print(e)\n",
    "    \n",
    "    cases_df = cases_df.sort_values(['file', 'Re', 'alpha'], ignore_index=True)\n",
    "    return cases_df\n",
    "\n",
    "\n",
    "def merge(cases_df, aerofoils_df):\n",
    "    cases_df['right_index'] = cases_df.index.tolist()\n",
    "\n",
    "    totdata_df = pd.merge(aerofoils_df, cases_df, on='file', how='outer', indicator=True)\n",
    "    data_df = totdata_df.loc[totdata_df._merge == 'both'].drop(columns=['_merge'])\n",
    "\n",
    "    dup, inds = list(data_df.right_index.duplicated()), data_df.index.tolist()\n",
    "    dup_inds = [i for i, d in zip(inds,dup) if d is True]\n",
    "    data_df = data_df[~data_df.index.isin(dup_inds)].drop(columns=['right_index'])\n",
    "    data_df = data_df.sort_values(['file', 'Re'], ascending=[True, True])\n",
    "\n",
    "    return cases_df, totdata_df, data_df\n",
    "\n",
    "\n",
    "def save_cases(df, file):\n",
    "    df.to_csv(file, index=False)\n",
    "    \n",
    "    \n",
    "def df_from_csv(file):\n",
    "    df = pd.read_csv(file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7750418c-4ecc-4a7f-9273-9f05909202fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cases_df = create_cases(directory='dat/case-dat', ext='csv')\n",
    "# save_cases(df=cases_df, file='dat-saved/cases-df.csv')\n",
    "# \n",
    "# ren_cases_df = create_cases(directory='dat/rennes-dat/case-dat', ext='txt')\n",
    "# save_cases(df=ren_cases_df, file='dat-saved/ren-cases-df.csv')\n",
    "# \n",
    "# exp_cases_df = create_cases(directory='dat/exp-dat/case-dat', ext='csv')\n",
    "# save_cases(df=exp_cases_df, file='dat-saved/exp-cases-df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f3a6612-6351-424b-aa50-4ed03ebb764d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cases_df = df_from_csv(file='dat-saved/cases-df.csv')\n",
    "ren_cases_df = df_from_csv(file='dat-saved/ren-cases-df.csv')\n",
    "exp_cases_df = df_from_csv(file='dat-saved/exp-cases-df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69895aee-3a29-4530-8f1a-70514e6c7d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 829544 831325 829544\n",
      "Rennes: 31526 31527 27641\n",
      "Experimental: 1012 2664 1012\n"
     ]
    }
   ],
   "source": [
    "cases_df, totdata_df, data_df = merge(aerofoils_df=aerofoils_df, cases_df=cases_df)\n",
    "print('Normal:', len(cases_df), len(totdata_df), len(data_df))\n",
    "\n",
    "ren_cases_df, ren_totdata_df, ren_data_df = merge(aerofoils_df=ren_aerofoils_df, cases_df=ren_cases_df)\n",
    "print('Rennes:', len(ren_cases_df), len(ren_totdata_df), len(ren_data_df))\n",
    "\n",
    "exp_cases_df, exp_totdata_df, exp_data_df = merge(aerofoils_df=aerofoils_df, cases_df=exp_cases_df)\n",
    "print('Experimental:', len(exp_cases_df), len(exp_totdata_df), len(exp_data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3f4358b-38c6-4b83-b4ef-f83d759c5551",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_df.sample(frac=0.00001).drop(columns = ['spline', 'xy_profile'])\n",
    "# list(set(ren_data_df.file.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
